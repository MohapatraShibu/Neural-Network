{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_text_generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW9H8Eg5Ie3i",
        "colab_type": "text"
      },
      "source": [
        "https://colab.research.google.com/drive/1riwAm3M-YeYreFbRTYhw0BwZs9Nff5Pg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqKthXWR0jLR",
        "colab_type": "code",
        "outputId": "3544ce7b-cf3a-432f-9d15-5bb82d69cf9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget http://www.gutenberg.org/files/11/11-0.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-02 09:06:08--  http://www.gutenberg.org/files/11/11-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 173595 (170K) [text/plain]\n",
            "Saving to: ‘11-0.txt’\n",
            "\n",
            "11-0.txt            100%[===================>] 169.53K   357KB/s    in 0.5s    \n",
            "\n",
            "2019-10-02 09:06:09 (357 KB/s) - ‘11-0.txt’ saved [173595/173595]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3CeZ5xA1ElA",
        "colab_type": "code",
        "outputId": "9250ca66-1c1c-44b6-d703-a25167540085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation\n",
        "from keras.layers.recurrent import SimpleRNN\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osvlz83O1F0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fin=open('11-0.txt',encoding='utf-8-sig')\n",
        "lines=[]\n",
        "for line in fin:\n",
        "  line = line.strip().lower()\n",
        "  #line = line.decode(\"ascii\",\"ignore\")\n",
        "  if(len(line)==0):\n",
        "    continue\n",
        "  lines.append(line)\n",
        "fin.close()\n",
        "text = \" \".join(lines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2_gdsU-1Ixo",
        "colab_type": "code",
        "outputId": "2e9d8804-ad5e-47ec-f5c5-037dc5922901",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text[52:100]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "', by lewis carroll this ebook is for the use of '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHXoBDvL1K6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "text = text.lower()\n",
        "text = re.sub('[^0-9a-zA-Z]+',' ',text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxJOfWom1Mat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "counts = Counter()\n",
        "counts.update(text.split())\n",
        "words = sorted(counts, key=counts.get, reverse=True)\n",
        "nb_words = len(text.split())\n",
        "word2index = {word: i for i, word in enumerate(words)}\n",
        "index2word = {i: word for i, word in enumerate(words)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbQYWOas1N57",
        "colab_type": "code",
        "outputId": "ae065b7f-525d-4fef-a2ff-22b9c47ded05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "SEQLEN = 10\n",
        "STEP = 1\n",
        "input_words = []\n",
        "label_words = []\n",
        "text2=text.split()\n",
        "for i in range(0,nb_words-SEQLEN,STEP):\n",
        "    x=text2[i:(i+SEQLEN)]\n",
        "    y=text2[i+SEQLEN]\n",
        "    input_words.append(x)\n",
        "    label_words.append(y)\n",
        "print('input words list: ','\\n',input_words[0])\n",
        "print('label(output) words list: ','\\n',label_words[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input words list:  \n",
            " ['project', 'gutenberg', 's', 'alice', 's', 'adventures', 'in', 'wonderland', 'by', 'lewis']\n",
            "label(output) words list:  \n",
            " carroll\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPu4sHX11PVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_words = len(set(words))\n",
        "X = np.zeros((len(input_words), SEQLEN, total_words), dtype=np.bool)\n",
        "y = np.zeros((len(input_words), total_words), dtype=np.bool)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkt3HHKx1Q_Q",
        "colab_type": "code",
        "outputId": "f38c6cca-3a98-430e-a5a7-439a6474f631",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "for i, input_word in enumerate(input_words):\n",
        "     for j, word in enumerate(input_word):\n",
        "         X[i, j, word2index[word]] = 1\n",
        "     y[i,word2index[label_words[i]]]=1\n",
        "print('Shape of X: ',X.shape)\n",
        "print('Shape of y: ',y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X:  (30527, 10, 3043)\n",
            "Shape of y:  (30527, 3043)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF_3YL7i1Scu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 32\n",
        "NUM_ITERATIONS = 100\n",
        "NUM_EPOCHS_PER_ITERATION = 1\n",
        "NUM_PREDS_PER_EPOCH = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO6h_MM6pn0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9UMphCo1UX2",
        "colab_type": "code",
        "outputId": "d15907f9-10f5-4dcd-f622-1151024f294d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(HIDDEN_SIZE,return_sequences=False,input_shape=(SEQLEN,total_words)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 128)               1624064   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3043)              392547    \n",
            "=================================================================\n",
            "Total params: 2,016,611\n",
            "Trainable params: 2,016,611\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz28sfwJxtDb",
        "colab_type": "code",
        "outputId": "31ac9073-eeb8-4b01-ac24-7b3b1393b9b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "int(len(input_words)*0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3052"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3kUVDt8xwgs",
        "colab_type": "code",
        "outputId": "0d8fa933-9f82-4d73-f78f-0ab712a40b9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(input_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30527"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz7hogU1uVhv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for iteration in range(50):\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Iteration #: %d\" % (iteration))\n",
        "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION, validation_split = 0.1)\n",
        "    test_idx = np.random.randint(int(len(input_words)*0.1)) * (-1)\n",
        "    test_words = input_words[test_idx]\n",
        "    print(\"Generating from seed: %s\" % (test_words))\n",
        "    for i in range(NUM_PREDS_PER_EPOCH):        \n",
        "        Xtest = np.zeros((1, SEQLEN, total_words))\n",
        "        for i, ch in enumerate(test_words):\n",
        "            Xtest[0, i, word2index[ch]] = 1\n",
        "        pred = model.predict(Xtest, verbose=0)[0]\n",
        "        ypred = index2word[np.argmax(pred)]\n",
        "        print(ypred,end=' ')\n",
        "        test_words = test_words[1:] + [ypred]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBbBCum7-U8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import LSTM, Input, Bidirectional"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65d1LB92-U_D",
        "colab_type": "code",
        "outputId": "d6885f4c-7d94-4928-ab05-093899f4161a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE,return_sequences=False),input_shape=(SEQLEN,total_words)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_1 (Bidirection (None, 256)               3248128   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3043)              782051    \n",
            "=================================================================\n",
            "Total params: 4,030,179\n",
            "Trainable params: 4,030,179\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmeyHaRk-g4M",
        "colab_type": "code",
        "outputId": "74e71d47-d5d3-49ed-fd79-b574360ac8ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for iteration in range(50):\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Iteration #: %d\" % (iteration))\n",
        "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION, validation_split = 0.1)\n",
        "    test_idx = np.random.randint(int(len(input_words)*0.1)) * (-1)\n",
        "    test_words = input_words[test_idx]\n",
        "    print(\"Generating from seed: %s\" % (test_words))\n",
        "    for i in range(NUM_PREDS_PER_EPOCH):        \n",
        "        Xtest = np.zeros((1, SEQLEN, total_words))\n",
        "        for i, ch in enumerate(test_words):\n",
        "            Xtest[0, i, word2index[ch]] = 1\n",
        "        pred = model.predict(Xtest, verbose=0)[0]\n",
        "        ypred = index2word[np.argmax(pred)]\n",
        "        print(ypred,end=' ')\n",
        "        test_words = test_words[1:] + [ypred]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Iteration #: 0\n",
            "Train on 27474 samples, validate on 3053 samples\n",
            "Epoch 1/1\n",
            "27474/27474 [==============================] - 38s 1ms/step - loss: 6.1547 - val_loss: 8.0670\n",
            "Generating from seed: ['work', 'by', 'people', 'who', 'agree', 'to', 'be', 'bound', 'by', 'the']\n",
            "little little little little of the little little little little little little little of the little little little little little little little of the little little little little little little little of the little little little little little little little of the little little little little little little little of the little little little little little little little of the little little little little little little little of the little little little little little little little of the little little little little little little little of the little little little little little little little of the little little little little ==================================================\n",
            "Iteration #: 1\n",
            "Train on 27474 samples, validate on 3053 samples\n",
            "Epoch 1/1\n",
            "27474/27474 [==============================] - 36s 1ms/step - loss: 5.6239 - val_loss: 8.6274\n",
            "Generating from seed: ['a', 'few', 'things', 'that', 'you', 'can', 'do', 'with', 'most', 'project']\n",
            "i m you said the hatter i m you said the hatter i m you said the hatter i m you said the hatter i m you said the hatter i m you said the hatter i m you said the hatter i m you said the hatter i m you said the hatter i m you said the hatter i m you said the hatter i m you said the hatter i m you said the hatter i m you said the hatter i m you said the hatter i m you said the hatter i m you said ==================================================\n",
            "Iteration #: 2\n",
            "Train on 27474 samples, validate on 3053 samples\n",
            "Epoch 1/1\n",
            "27474/27474 [==============================] - 36s 1ms/step - loss: 5.1264 - val_loss: 8.7942\n",
            "Generating from seed: ['than', 'are', 'set', 'forth', 'in', 'this', 'agreement', 'you', 'must', 'obtain']\n",
            "the mock turtle said alice i m a little of of the mock turtle said alice i m a little of of the mock turtle said alice i m a little of of the mock turtle said alice i m a little of of the mock turtle said alice i m a little of of the mock turtle said alice i m a little of of the mock turtle said alice i m a little of of the mock turtle said alice i m a little of of the mock turtle said alice i m a little of of the ==================================================\n",
            "Iteration #: 3\n",
            "Train on 27474 samples, validate on 3053 samples\n",
            "Epoch 1/1\n",
            "27474/27474 [==============================] - 36s 1ms/step - loss: 4.6695 - val_loss: 9.0838\n",
            "Generating from seed: ['you', 'provide', 'in', 'accordance', 'with', 'paragraph', '1', 'f', '3', 'a']\n",
            "little little head and she was been to see it was a little little thing and she was a little little little thing and she was been to see it was a little little thing and she was a little little little thing and she was been to see it was a little little thing and she was a little little little thing and she was been to see it was a little little thing and she was a little little little thing and she was been to see it was a little little thing and she was a little ==================================================\n",
            "Iteration #: 4\n",
            "Train on 27474 samples, validate on 3053 samples\n",
            "Epoch 1/1\n",
            "27474/27474 [==============================] - 36s 1ms/step - loss: 4.2415 - val_loss: 9.3258\n",
            "Generating from seed: ['works', 'and', 'the', 'medium', 'on', 'which', 'they', 'may', 'be', 'stored']\n",
            "the queen and the queen was to a little little key and she went on to the other side of the door and the other of the door of the door was a little little key and she went on to her and she had been out of the house and she was not to the little key and she was quite to the door and she went on the door and she was the little key and she was quite quite to the door and she was the little key and she was quite quite to the door and ==================================================\n",
            "Iteration #: 5\n",
            "Train on 27474 samples, validate on 3053 samples\n",
            "Epoch 1/1\n",
            "27474/27474 [==============================] - 36s 1ms/step - loss: 3.8033 - val_loss: 9.6437\n",
            "Generating from seed: ['of', 'a', 'project', 'gutenberg', 'tm', 'work', 'any', 'work', 'on', 'which']\n",
            "in the queen of the court and the queen and began to itself and then the other of the door and then the queen was silent and looked at the other of the queen who had been been to the other of the other side of the court and the queen was silent and looked at the other time and the queen was silent and looked at the queen and the queen and began to itself and she went on to herself and she did not like to say it was the cat and she had been a little idea ==================================================\n",
            "Iteration #: 6\n",
            "Train on 27474 samples, validate on 3053 samples\n",
            "Epoch 1/1\n",
            "27474/27474 [==============================] - 36s 1ms/step - loss: 3.3480 - val_loss: 9.8548\n",
            "Generating from seed: ['works', 'to', 'protect', 'the', 'project', 'gutenberg', 'tm', 'concept', 'and', 'trademark']\n",
            "s in a low voice and the moral of that s is and she said the gryphon and she went on to herself and she had been quite to her own feet she found herself in a little golden leaves and she had to get into one of her face and was quite about in a wood she heard a little pattering of them in the wood which said the caterpillar to herself and she was out of sight and it was quite quite than to alice and she went on about her and she had been seen very very ==================================================\n",
            "Iteration #: 7\n",
            "Train on 27474 samples, validate on 3053 samples\n",
            "Epoch 1/1\n",
            "27474/27474 [==============================] - 36s 1ms/step - loss: 2.8857 - val_loss: 10.1880\n",
            "Generating from seed: ['gutenberg', 'org', 'this', 'web', 'site', 'includes', 'information', 'about', 'project', 'gutenberg']\n",
            "and alice s adventures in wonderland lewis carroll posting fulcrum fulcrum 3 0 those ebook alice were of all three white kid gloves and she had been to see it was very carefully so she tried to herself down and ran up to see she was going to see it was very uncomfortable and she had quite quite finished to the table but it was going to get out again she had been quite out of sight and it was so much late that she had been about it had fallen into a large pig and she said in a ==================================================\n",
            "Iteration #: 8\n",
            "Train on 27474 samples, validate on 3053 samples\n",
            "Epoch 1/1\n",
            "27474/27474 [==============================] - 36s 1ms/step - loss: 2.4206 - val_loss: 10.4369\n",
            "Generating from seed: ['including', 'how', 'to', 'make', 'donations', 'to', 'the', 'project', 'gutenberg', 'literary']\n",
            "alice s adventures in wonderland author lewis carroll posting 25 edition 11 11 whatsoever chapter chapter xii the lobster this rabbit away that s worth in the window as it had the hookah of them and they made from him so they re a consultation about the end of the lobster but it would be no doubt but she had not a long fancy and she was a curious watch to be beheaded and she was going to find that it s a vegetable it doesn t look at any rate it said it s a very fine way you ==================================================\n",
            "Iteration #: 9\n",
            "Train on 27474 samples, validate on 3053 samples\n",
            "Epoch 1/1\n",
            "27474/27474 [==============================] - 36s 1ms/step - loss: 1.9870 - val_loss: 10.6765\n",
            "Generating from seed: ['support', 'and', 'donations', 'to', 'carry', 'out', 'its', 'mission', 'of', 'increasing']\n",
            "and the table down in a little shriek and was just in going to hear the door and such a little tail and four hours in a long way on the queen will you took you know and the gryphon went on in a trembling voice to his head we cried the queen and who were passing at the moment the cook are you are you know said the king and i m not you know said alice who was not like to do anything but she went on the door and soon up and led a moment she found ==================================================\n",
            "Iteration #: 10\n",
            "Train on 27474 samples, validate on 3053 samples\n",
            "Epoch 1/1\n",
            "27474/27474 [==============================] - 36s 1ms/step - loss: 1.6000 - val_loss: 10.8613\n",
            "Generating from seed: ['states', 'and', 'you', 'are', 'located', 'in', 'the', 'united', 'states', 'we']\n",
            "beg your pardon cried alice hastily looked at all the mouse was sitting on the court and in a large voice with the bread and butter just in confusion confusion the queen was out of his pocket and they sat at the dormouse who was closed at this time and the whole creatures unrolled itself and and the birds of themselves that oh i wonder what latitude a tiny plan will do alice much under a tree of the dodo went close to the table i think i d better better said alice she looked at once and the queen ==================================================\n",
            "Iteration #: 11\n",
            "Train on 27474 samples, validate on 3053 samples\n",
            "Epoch 1/1\n",
            "27474/27474 [==============================] - 36s 1ms/step - loss: 1.2647 - val_loss: 11.3111\n",
            "Generating from seed: ['using', 'the', 'method', 'you', 'already', 'use', 'to', 'calculate', 'your', 'applicable']\n",
            "oh what to be about she said the cat and she got to herself and see what was quite about as she said the gryphon and it was to fancy that she had quite executed on her girls like a large of this way she came a little rose tree there s the duchess of no thing said in the gryphon she added the best thing the world you saw what a little girl she heard it had going to look into the air i don t want to stay down you re quite sure that i m a poor ==================================================\n",
            "Iteration #: 12\n",
            "Train on 27474 samples, validate on 3053 samples\n",
            "Epoch 1/1\n",
            "27474/27474 [==============================] - 36s 1ms/step - loss: 0.9837 - val_loss: 11.4004\n",
            "Generating from seed: ['discovered', 'and', 'reported', 'to', 'you', 'within', '90', 'days', 'of', 'receipt']\n",
            "and then said the gryphon and you are old said the youth i never heard a serpent said alice i m not said the cat said the queen s watch said alice and that it was much beginning the cook to eat one seemed to the little shriek and the table and a little door was vanished a little small key and the door as she went on and soon would her lips to make everything something sure she is not as much as well the rabbit and she heard a little pattering of hands and in the distance and ==================================================\n",
            "Iteration #: 13\n",
            "Train on 27474 samples, validate on 3053 samples\n",
            "Epoch 1/1\n",
            "27474/27474 [==============================] - 36s 1ms/step - loss: 0.7499 - val_loss: 11.6115\n",
            "Generating from seed: ['active', 'links', 'or', 'immediate', 'access', 'to', 'the', 'full', 'terms', 'of']\n",
            "yourself you re all my adventures said the duchess the dog s become tone you you know you remarked on four story you can t said the cat and she added in a long tone and an m is to my tail oh you like to my thing i think i can be a little bit said alice in a hurry to change the subject of conversation are you are you fond of of dogs the mouse did not answer so alice went on eagerly like a jack to the creatures and call after the one of two while the ==================================================\n",
            "Iteration #: 14\n",
            "Train on 27474 samples, validate on 3053 samples\n",
            "Epoch 1/1\n",
            "27474/27474 [==============================] - 36s 1ms/step - loss: 0.5593 - val_loss: 11.8018\n",
            "Generating from seed: ['not', 'solicit', 'donations', 'in', 'locations', 'where', 'we', 'have', 'not', 'received']\n",
            "idea and then they began with a growl and its adventures half done this time alice had no speech in the three faces but the world was shut to get out again the rabbit hole went straight on like a tunnel for some way and then dipped suddenly down so suddenly that alice had not a moment to be beheaded that for the time had put his tea and bread more white getting throw on the lobsters and the gryphon up and staring at the other other ten change and while some time the other difficulty was a flamingo was ==================================================\n",
            "Iteration #: 15\n",
            "Train on 27474 samples, validate on 3053 samples\n",
            "Epoch 1/1\n",
            "27474/27474 [==============================] - 36s 1ms/step - loss: 0.4040 - val_loss: 12.0111\n",
            "Generating from seed: ['terms', 'will', 'be', 'linked', 'to', 'the', 'project', 'gutenberg', 'tm', 'license']\n",
            "with this ebook alice slipped in at this moment so think of nothing to nothing to the first first of the end of the bill s voice and alice called out by the hatter here just just suppressed by the roof that each paw as to be my way than that she thought alice could have had to through any time she said the cat and suddenly upon a sudden eyes with each way she found it so very much of the house to think she waited found first to see she had to through it was very provoking to ==================================================\n",
            "Iteration #: 16\n",
            "Train on 27474 samples, validate on 3053 samples\n",
            "Epoch 1/1\n",
            "12864/27474 [=============>................] - ETA: 18s - loss: 0.2497"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Rfep49Ht_V-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}