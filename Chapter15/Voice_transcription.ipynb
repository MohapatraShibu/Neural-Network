{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Voice_transcription.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPWJzHJn377E",
        "colab_type": "text"
      },
      "source": [
        "https://colab.research.google.com/drive/1Z3V1FpkmXZyFUXjff1qvvRFTlMZNsFrd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7UoI7LbuwtX",
        "colab_type": "code",
        "outputId": "ca8a7c90-b3e9-4139-930b-551253340f00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget http://www.openslr.org/resources/12/train-clean-100.tar.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-03 03:16:37--  http://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6387309499 (5.9G) [application/x-gzip]\n",
            "Saving to: ‘train-clean-100.tar.gz’\n",
            "\n",
            "train-clean-100.tar 100%[===================>]   5.95G   148MB/s    in 49s     \n",
            "\n",
            "2019-10-03 03:17:26 (125 MB/s) - ‘train-clean-100.tar.gz’ saved [6387309499/6387309499]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4PLc0w8u1hI",
        "colab_type": "code",
        "outputId": "c4c66687-a7db-4d48-c0a3-4b5410e6496e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  train-clean-100.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32leG9y9uy5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xzvf train-clean-100.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcPUyVDvw_5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqsodctKvzSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, numpy as np\n",
        "org_path = '/content/LibriSpeech/train-clean-100/'\n",
        "count = 0\n",
        "inp = []\n",
        "k=0\n",
        "audio_name = []\n",
        "audio_trans = []\n",
        "for dir1 in os.listdir(org_path):\n",
        "  dir2_path = org_path+dir1+'/'\n",
        "  #print(dir2_path)\n",
        "  for dir2 in os.listdir(dir2_path):\n",
        "    dir3_path = dir2_path+dir2+'/'\n",
        "    \n",
        "    for audio in os.listdir(dir3_path):\n",
        "      if audio.endswith('.txt'):\n",
        "        k+=1\n",
        "        file_path = dir3_path + audio\n",
        "        with open(file_path) as f:\n",
        "          line = f.readlines()\n",
        "          for lines in line:\n",
        "            audio_name.append(dir3_path+lines.split()[0]+'.flac')\n",
        "            words2 = lines.split()[1:]\n",
        "            words4=' '.join(words2)\n",
        "            audio_trans.append(words4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4WqQArywN4m",
        "colab_type": "code",
        "outputId": "c7dd0af6-1573-4547-c596-3ff499b86ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(audio_name)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28539"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IbofEtc1F6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "len_audio_name=[]\n",
        "for i in range(len(audio_name)):\n",
        "  tt = re.sub(' ','-',audio_trans[i])\n",
        "  len_audio_name.append(len(tt))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLzCQVDwxbB2",
        "colab_type": "code",
        "outputId": "3ec817fc-b2dc-4855-9dbb-17de54981867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max(len_audio_name)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "398"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B3sJvFdoJ7h",
        "colab_type": "code",
        "outputId": "dcaf7767-55a2-4516-866e-2402a77172d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.hist(len_audio_name)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([8.590e+02, 1.692e+03, 1.913e+03, 3.588e+03, 7.855e+03, 8.685e+03,\n",
              "        3.443e+03, 4.790e+02, 2.300e+01, 2.000e+00]),\n",
              " array([  8.,  47.,  86., 125., 164., 203., 242., 281., 320., 359., 398.]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAEhSpwwASeqUASBJnfo/UZ+hNm+gjhAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ8QkIDWoWXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_audio_name = []\n",
        "final_audio_trans = []\n",
        "for i in range(len(audio_name)):\n",
        "  if(len_audio_name[i]<100):\n",
        "    final_audio_name.append(audio_name[i])\n",
        "    final_audio_trans.append(audio_trans[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e779DFDxz_2",
        "colab_type": "code",
        "outputId": "474881af-b748-4006-e8aa-39f8747d5577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "inp = []\n",
        "inp2 = []\n",
        "op = []\n",
        "op2 = []\n",
        "count = 0\n",
        "for j in range(len(final_audio_name)):\n",
        "  t = librosa.core.load(final_audio_name[j],sr=16000, mono= True)\n",
        "  \n",
        "  if(t[0].shape[0]<160000):\n",
        "    count+=1\n",
        "    t = np.array(t[0])\n",
        "    t2 = np.zeros(160000)\n",
        "    t2[:len(t)] = t\n",
        "    inp = []\n",
        "    for i in range(t2.shape[0]//160 - 1):\n",
        "      k = t2[(i*160):((i*160)+320)]\n",
        "      fft = np.fft.rfft(k)\n",
        "      inp.append(np.abs(fft))\n",
        "    inp2.append(inp)\n",
        "    op2.append(final_audio_trans[j])\n",
        "    if(j%50==0):\n",
        "      print(j, count)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1\n",
            "100 76\n",
            "150 126\n",
            "200 176\n",
            "250 226\n",
            "300 275\n",
            "350 325\n",
            "400 375\n",
            "450 425\n",
            "500 475\n",
            "550 525\n",
            "600 575\n",
            "650 623\n",
            "700 673\n",
            "750 723\n",
            "800 773\n",
            "850 823\n",
            "900 873\n",
            "950 923\n",
            "1000 973\n",
            "1050 1023\n",
            "1100 1073\n",
            "1150 1123\n",
            "1200 1173\n",
            "1250 1223\n",
            "1350 1322\n",
            "1400 1372\n",
            "1450 1422\n",
            "1500 1472\n",
            "1550 1522\n",
            "1600 1572\n",
            "1650 1622\n",
            "1700 1672\n",
            "1750 1722\n",
            "1800 1771\n",
            "1850 1821\n",
            "1900 1871\n",
            "1950 1921\n",
            "2000 1971\n",
            "2050 2020\n",
            "2100 2070\n",
            "2150 2120\n",
            "2200 2168\n",
            "2250 2218\n",
            "2300 2267\n",
            "2350 2317\n",
            "2400 2367\n",
            "2450 2417\n",
            "2500 2467\n",
            "2550 2517\n",
            "2600 2566\n",
            "2650 2616\n",
            "2700 2666\n",
            "2750 2716\n",
            "2800 2766\n",
            "2850 2816\n",
            "2900 2866\n",
            "2950 2915\n",
            "3000 2962\n",
            "3050 3012\n",
            "3100 3061\n",
            "3150 3111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFSrv_Zlo_eD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRB4jbnWD2ws",
        "colab_type": "code",
        "outputId": "ce960613-a7e4-49e4-e81c-c611ab728798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "j"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-PSvX4u03JG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "list2d = op2\n",
        "charList = list(set(list(itertools.chain(*list2d))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btIicux-05Wg",
        "colab_type": "code",
        "outputId": "7815086c-4c39-4fa6-e095-afb039afd7f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(charList)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hSksSsc4U66",
        "colab_type": "code",
        "outputId": "54ec9d3d-692b-444a-936f-45d60ffa86d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_audio = len(op2)\n",
        "num_audio"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3153"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyzFF49H0T4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "y2 = []\n",
        "input_lengths = np.ones((num_audio,1))*243\n",
        "label_lengths = np.zeros((num_audio,1))\n",
        "for i in range(num_audio):\n",
        "    val = list(map(lambda x: charList.index(x), op2[i]))\n",
        "    while len(val)<243:\n",
        "        val.append(29)\n",
        "    y2.append(val)\n",
        "    label_lengths[i] = len(op2[i])\n",
        "    #input_lengths[i] = len(val)\n",
        "    input_lengths[i] = 243"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3CRq1UOxSRt",
        "colab_type": "code",
        "outputId": "3701e36e-8212-406a-8c35-f13fc9caa048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.max(label_lengths)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wJBV6ov-Bki",
        "colab_type": "code",
        "outputId": "586097ea-4fb3-4ad7-acad-0dd5decfb780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.min(label_lengths)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EarL-tFM-LFN",
        "colab_type": "code",
        "outputId": "8f0fe097-15b0-4b2e-860c-7105bcc99109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.percentile(label_lengths, 25)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQiNYtgf6BKX",
        "colab_type": "code",
        "outputId": "cdc3975f-20b5-46a4-a530-ec616e94e286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "inp2[1][0].shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(161,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKL1eNZQ6Wct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHUukSWG5Iw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "x = np.asarray(inp2)\n",
        "y2 = np.asarray(y2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0jQ70oT5S8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "outputs = {'ctc': np.zeros([32])}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGhWFcjJ5U_m",
        "colab_type": "code",
        "outputId": "208bd116-a5f0-4ccb-a21d-d44efbf4805a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras.backend as K\n",
        "def ctc_loss(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGgGO1D35WvD",
        "colab_type": "code",
        "outputId": "06e1d35a-8bb9-4e59-9265-15c2c76f3c65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "audio_trans[0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"THE EVENING PASSED ON MADAME DE VILLEFORT EXPRESSED A DESIRE TO RETURN TO PARIS WHICH MADAME DANGLARS HAD NOT DARED TO DO NOTWITHSTANDING THE UNEASINESS SHE EXPERIENCED ON HIS WIFE'S REQUEST M DE VILLEFORT\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFNbiacW5vix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical,np_utils\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D,Dropout, Activation, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Convolution2D, MaxPooling2D,Conv2D, Reshape, GRU, TimeDistributed, Lambda\n",
        "from keras.models import Model\n",
        "import random\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM , Bidirectional,Dropout, BatchNormalization\n",
        "from keras import backend as K\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras import regularizers\n",
        "from keras.layers.merge import add, concatenate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOYevJyt51mz",
        "colab_type": "code",
        "outputId": "28399599-e938-4d98-8b98-987611f6cbe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "input_data = Input(name='the_input', shape = (999,161), dtype='float32')\n",
        "inp = BatchNormalization(name=\"inp\")(input_data)\n",
        "conv= Conv1D(filters=220, kernel_size = 11,strides = 2, padding='valid',activation='relu')(inp)\n",
        "conv = BatchNormalization(name=\"Normal0\")(conv)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDqinc7bvJ8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv1= Conv1D(filters=220, kernel_size = 11,strides = 2, padding='valid',activation='relu')(conv)\n",
        "conv1 = BatchNormalization(name=\"Normal_0\")(conv1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2TiAVdY51sD",
        "colab_type": "code",
        "outputId": "e1d52541-5735-4500-8e22-2133988b50fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "gru_3 = GRU(512, return_sequences = True, name = 'gru_3')(conv1)\n",
        "gru_4 = GRU(512, return_sequences = True, go_backwards = True, name = 'gru_4')(conv1)\n",
        "\n",
        "merged = concatenate([gru_3, gru_4])\n",
        "normalized = BatchNormalization(name=\"Normal\")(merged)\n",
        "dense = TimeDistributed(Dense(30))(normalized)\n",
        "y_pred = TimeDistributed(Activation('softmax', name='softmax'))(dense)\n",
        "\n",
        "Model(inputs = input_data, outputs = y_pred).summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "the_input (InputLayer)          (None, 999, 161)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "inp (BatchNormalization)        (None, 999, 161)     644         the_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 495, 220)     389840      inp[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "Normal0 (BatchNormalization)    (None, 495, 220)     880         conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 243, 220)     532620      Normal0[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Normal_0 (BatchNormalization)   (None, 243, 220)     880         conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "gru_3 (GRU)                     (None, 243, 512)     1125888     Normal_0[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "gru_4 (GRU)                     (None, 243, 512)     1125888     Normal_0[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 243, 1024)    0           gru_3[0][0]                      \n",
            "                                                                 gru_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Normal (BatchNormalization)     (None, 243, 1024)    4096        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 243, 30)      30750       Normal[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 243, 30)      0           time_distributed_1[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 3,211,486\n",
            "Trainable params: 3,208,236\n",
            "Non-trainable params: 3,250\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOSHUneZ51p-",
        "colab_type": "code",
        "outputId": "3b30ffba-0a91-425e-f784-3c5dea1a92ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "Optimizer = Adam(lr = 0.001)\n",
        "labels = Input(name = 'the_labels', shape=[243], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1],dtype='int64')\n",
        "label_length = Input(name='label_length',shape=[1],dtype='int64')\n",
        "output = Lambda(ctc_loss, output_shape=(1,),name='ctc')([y_pred, labels, input_length, label_length])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4551: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2X7uf7Z6bar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs = [input_data, labels, input_length, label_length], outputs= output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL5TTvPs6beY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "816e6152-5973-4d02-9b22-a309e74658ac"
      },
      "source": [
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = Optimizer, metrics = ['accuracy'])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZBn1pp66bkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(5000):\n",
        "  samp=random.sample(range(len(inp2)-25),32)\n",
        "  x3=[inp2[i] for i in samp]\n",
        "  x3 = np.array(x3)/100\n",
        "  #x3 = x3/np.max(x3)\n",
        "  y3 = [y2[i] for i in samp]\n",
        "  y3 = np.array(y3)\n",
        "  input_lengths2 = [input_lengths[i] for i in samp]\n",
        "  label_lengths2 = [label_lengths[i] for i in samp]\n",
        "  input_lengths2 = np.array(input_lengths2)\n",
        "  label_lengths2 = np.array(label_lengths2)\n",
        "  inputs = {\n",
        "    'the_input': x3,\n",
        "    'the_labels': y3,\n",
        "    'input_length': input_lengths2,\n",
        "    'label_length': label_lengths2,\n",
        "  }\n",
        "  outputs = {'ctc': np.zeros([32])}  \n",
        "  if(i%100==0):\n",
        "    print(i)\n",
        "    model.fit(inputs, outputs,batch_size = 32, epochs=3, verbose =1)\n",
        "    \n",
        "  else:\n",
        "    model.fit(inputs, outputs,batch_size = 32, epochs=3, verbose =0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1qjRsvfAvD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = Model(inputs = input_data, outputs = y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bSnkXjUAwxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k=-12\n",
        "pred= model2.predict(np.array(inp2[k]).reshape(1,999,161)/100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-T5gvWWsdNd",
        "colab_type": "code",
        "outputId": "464af823-f4b1-45c3-f6cf-a3ff43dc24a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred[0,:].shape, np.array(y2[k]).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((243, 30), (243,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wXLGeyiAw1G",
        "colab_type": "code",
        "outputId": "ad6fd129-7d9f-42f4-e79e-d28b0316bedd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "np.argmax(pred[0,:],axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([29, 29, 29, 29, 29, 29, 29, 11, 14, 29,  0, 18, 18, 26, 26,  2,  2,\n",
              "        0,  0,  4,  7,  7, 29, 29, 29, 29, 29, 29, 18, 18, 12, 13, 29,  0,\n",
              "        0, 11, 26, 18, 27, 13, 29, 29, 29, 29, 18, 18, 24, 26, 14,  8,  8,\n",
              "       10, 10, 10, 29, 29, 29, 29, 29, 29, 29, 29, 18, 18, 18, 26, 29,  0,\n",
              "        0,  0,  0, 11,  4, 18, 27, 26,  5, 20, 29, 18, 25, 25,  4,  1,  1,\n",
              "        1, 24,  8,  8,  2, 29, 18, 18, 23, 23, 26,  5, 29,  8,  8, 29,  8,\n",
              "        8,  8,  8,  1,  1,  1, 29, 29, 29, 29, 29, 29, 18, 18, 18,  1, 18,\n",
              "       18,  1,  1, 26, 29, 18, 10, 26, 26, 29,  2,  2, 29, 29, 29, 29, 29,\n",
              "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
              "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
              "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
              "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
              "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
              "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
              "       29, 29, 29, 29, 29])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4pKtRI_nYuZ",
        "colab_type": "code",
        "outputId": "d7e8f6db-fec7-4270-f34b-7ae71e8734c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y3[k][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4, 27, 15, 10,  3, 27, 16,  4, 27,  1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ekfq7vGA85s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder(pred):\n",
        "  pred_ints = (K.eval(K.ctc_decode(pred,[243])[0][0])).flatten().tolist()\n",
        "  #print(pred_ints)\n",
        "  out = \"\"\n",
        "  for i in range(len(pred_ints)):\n",
        "    if pred_ints[i]<28:\n",
        "      out = out+charList[pred_ints[i]]\n",
        "      \n",
        "  print(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuKurUNst9lf",
        "colab_type": "code",
        "outputId": "d5af6ae6-dad8-4ea2-e4f7-e5194e09bde4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "decoder(pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4303: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "HAT ONTED BYTHO MY POARL OTHE MOUG WESPRN FOURRS S SO LON\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCX5PcRM_HTN",
        "colab_type": "code",
        "outputId": "7ac444da-b8b4-4ed7-e397-f1a5d2cb293d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "out = \"\"\n",
        "for i in range(len(y2[k])):\n",
        "  try:\n",
        "    #print(y2[k][i])\n",
        "    out += charList[y2[k][i]]\n",
        "  except:\n",
        "    continue\n",
        "  \n",
        "print(out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I FOUND IT BY THE NINTH PARALLEL OFF THE NORTHWESTERN SHORES OF CEYLON\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}